{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1-pJyQr4lelAqZ4KICuo4szuzNL5UyNOw",
      "authorship_tag": "ABX9TyOmdpbXIT2Uj9O13y68XntI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikeroguez/experimento/blob/main/Merge_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAhPiBtMepPv",
        "outputId": "15fe7539-8e90-444b-d647-cc2d56b158a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset consolidado guardado en /content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/2. Para unir/merged_dataset.csv\n"
          ]
        }
      ],
      "source": [
        "# Importar bibliotecas necesarias\n",
        "import pandas as pd\n",
        "\n",
        "# Cargar los datasets desde archivos locales\n",
        "assignments_path = \"/content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/1. Para tratar/tareas/tareas_consolidado_cleaned_sin_cursos_reutilizados.csv\"\n",
        "exams_path = \"/content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/1. Para tratar/examenes/examenes_consolidados.csv\"\n",
        "access_path = \"/content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/1. Para tratar/accesos/accesos_consolidado_cleaned.csv\"\n",
        "forums_path = \"/content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/1. Para tratar/foros/foros_consolidado.csv\"\n",
        "\n",
        "assignments_df = pd.read_csv(assignments_path)\n",
        "exams_df = pd.read_csv(exams_path)\n",
        "access_df = pd.read_csv(access_path)\n",
        "forums_df = pd.read_csv(forums_path)\n",
        "\n",
        "# 1. Integrar \"Exams\" a \"Assignments\" basado en groupKey y email\n",
        "merged_df = pd.merge(assignments_df, exams_df, how=\"left\", on=[\"groupKey\", \"email\"])\n",
        "\n",
        "# 2. Integrar \"Access\" a la base intermedia usando curso, groupKey y email\n",
        "merged_df = pd.merge(merged_df, access_df, how=\"left\", on=[\"curso\", \"groupKey\", \"email\"])\n",
        "\n",
        "# 3. Integrar \"Forums\" a la base intermedia usando curso, groupKey y email\n",
        "merged_df = pd.merge(merged_df, forums_df, how=\"left\", on=[\"curso\", \"groupKey\", \"email\"])\n",
        "\n",
        "# 4. Exportar el dataset consolidado\n",
        "output_path = \"/content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/2. Para unir/merged_dataset.csv\"\n",
        "merged_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Dataset consolidado guardado en {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Limpieza de examenes, accesos y foros**"
      ],
      "metadata": {
        "id": "fDy4hn4M_ys6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Definir rutas de entrada y salida\n",
        "input_path = \"/content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/2. Para unir/merged_dataset.csv\"\n",
        "output_path = \"/content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/2. Para unir/merged_cleaned_dataset.csv\"\n",
        "\n",
        "# Cargar el dataset\n",
        "df = pd.read_csv(input_path)\n",
        "\n",
        "### 1. MANEJO DE EXÁMENES\n",
        "\n",
        "# Contar estudiantes con datos de exámenes por curso\n",
        "exam_distribution = df.groupby(\"curso\")[\"total_assigned_exams\"].count()\n",
        "total_students_per_group = df.groupby(\"curso\")[\"email\"].count()\n",
        "\n",
        "# Identificar los casos de exámenes\n",
        "courses_with_all_exams = exam_distribution[exam_distribution == total_students_per_group].index  # Caso 0\n",
        "courses_without_exams = exam_distribution[exam_distribution == 0].index  # Caso 1\n",
        "courses_some_missing_exams = exam_distribution[\n",
        "    (exam_distribution / total_students_per_group >= 0.95) & (exam_distribution / total_students_per_group < 1)\n",
        "].index  # Caso 2\n",
        "courses_few_exams = exam_distribution[\n",
        "    (exam_distribution / total_students_per_group <= 0.05) & (exam_distribution / total_students_per_group > 0)\n",
        "].index  # Caso 3\n",
        "\n",
        "# Inicializar la variable \"no_exam_data\" en 0\n",
        "df[\"no_exam_data\"] = 0\n",
        "\n",
        "# Asignar los casos a los registros que no tienen datos en total_assigned_exams (NaN)\n",
        "df.loc[df[\"total_assigned_exams\"].isna(), \"no_exam_data\"] = 1  # Caso 1 por defecto\n",
        "\n",
        "# Aplicar los casos 2 y 3 incluso si ya fueron marcados como 1\n",
        "df.loc[(df[\"curso\"].isin(courses_some_missing_exams)) & (df[\"total_assigned_exams\"].isna()), \"no_exam_data\"] = 2  # Caso 2\n",
        "df.loc[(df[\"curso\"].isin(courses_few_exams)) & (df[\"total_assigned_exams\"].isna()), \"no_exam_data\"] = 3  # Caso 3\n",
        "\n",
        "### 2. MANEJO DE ACCESOS\n",
        "\n",
        "# Lista de variables de acceso\n",
        "access_variables = [\n",
        "    \"total_time\", \"average_time\", \"active_days_count\",\n",
        "    \"desktop_sessions_count\", \"mobile_sessions_count\",\n",
        "    \"desktop_imputed_session_time_count\", \"mobile_imputed_session_time_count\",\n",
        "    \"total_sessions_count\", \"total_imputed_session_time_count\", \"imputed_ratio\"\n",
        "]\n",
        "\n",
        "# Crear la variable \"missing_access_data\" (1 si todas las variables de acceso están ausentes)\n",
        "df[\"missing_access_data\"] = df[access_variables].isnull().all(axis=1).astype(int)\n",
        "\n",
        "# Contar registros sin datos de acceso\n",
        "missing_access_records = df[\"missing_access_data\"].sum()\n",
        "\n",
        "# Contar grupos completos sin datos de acceso\n",
        "missing_access_groups = df.groupby(\"curso\")[\"missing_access_data\"].mean()\n",
        "missing_access_groups = (missing_access_groups == 1).sum()  # Contar solo grupos donde todos los registros no tienen acceso\n",
        "\n",
        "### 3. MANEJO DE FOROS\n",
        "\n",
        "# Lista de variables de foros\n",
        "forum_variables = [\n",
        "    \"total_interacciones\", \"foros_unicos\", \"primer_interaccion\",\n",
        "    \"ultima_interaccion\", \"rango_tiempo\"\n",
        "]\n",
        "\n",
        "# Crear la variable \"no_forum_data\" (1 si todas las variables de foros están ausentes)\n",
        "df[\"no_forum_data\"] = df[forum_variables].isnull().all(axis=1).astype(int)\n",
        "\n",
        "# Rellenar variables de conteo con 0 sin usar inplace=True\n",
        "df[\"total_interacciones\"] = df[\"total_interacciones\"].fillna(0)\n",
        "df[\"foros_unicos\"] = df[\"foros_unicos\"].fillna(0)\n",
        "df[\"rango_tiempo\"] = df[\"rango_tiempo\"].fillna(0)\n",
        "\n",
        "# Mantener \"primer_interaccion\" y \"ultima_interaccion\" como NaN\n",
        "# df[\"primer_interaccion\"].fillna(\"2000-01-01\", inplace=True)  # Esta línea se eliminó para dejar NaN\n",
        "# df[\"ultima_interaccion\"].fillna(\"2000-01-01\", inplace=True)  # Esta línea se eliminó para dejar NaN\n",
        "\n",
        "# Contar el número total de cursos sin foros\n",
        "courses_without_forums = df.groupby(\"curso\")[\"no_forum_data\"].mean()\n",
        "courses_without_forums = (courses_without_forums == 1).sum()  # Contar solo los cursos donde todos los registros no tienen foros\n",
        "\n",
        "### 4. IMPRESIÓN DE RESULTADOS\n",
        "\n",
        "print(\"\\n Distribución de Casos por Curso (Exámenes):\")\n",
        "print(f\" Caso 1 - Cursos sin exámenes: {len(courses_without_exams)}\")\n",
        "print(f\" Caso 2 - Cursos donde todos tienen exámenes: {len(courses_with_all_exams)}\")\n",
        "print(f\" Caso 3 - Cursos con solo 5% alumnos sin exámenes: {len(courses_some_missing_exams)}\")\n",
        "print(f\" Caso 4 - Cursos con solo 95% alumnos sin exámenes: {len(courses_few_exams)}\")\n",
        "\n",
        "print(\"\\n Análisis de Datos Faltantes en Accesos:\")\n",
        "print(f\" Total de registros individuales sin datos de acceso: {missing_access_records}\")\n",
        "print(f\" Total de grupos (curso) donde todos los estudiantes no tienen datos de acceso: {missing_access_groups}\")\n",
        "\n",
        "print(\"\\n Análisis de Datos Faltantes en Foros:\")\n",
        "print(f\" Total de registros individuales sin datos de foros: {df['no_forum_data'].sum()}\")\n",
        "print(f\" Total de cursos (curso) sin foros: {courses_without_forums}\")\n",
        "\n",
        "### 5. GUARDAR EL DATASET LIMPIO\n",
        "\n",
        "df.to_csv(output_path, index=False)\n",
        "print(f\"\\n Dataset limpio guardado en: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLWPtKpb_1kY",
        "outputId": "d0adfd09-0c12-4580-b3e7-d2b78080919e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Distribución de Casos por Curso (Exámenes):\n",
            " Caso 1 - Cursos sin exámenes: 23\n",
            " Caso 2 - Cursos donde todos tienen exámenes: 140\n",
            " Caso 3 - Cursos con solo 5% alumnos sin exámenes: 30\n",
            " Caso 4 - Cursos con solo 95% alumnos sin exámenes: 1\n",
            "\n",
            " Análisis de Datos Faltantes en Accesos:\n",
            " Total de registros individuales sin datos de acceso: 2266\n",
            " Total de grupos (curso) donde todos los estudiantes no tienen datos de acceso: 54\n",
            "\n",
            " Análisis de Datos Faltantes en Foros:\n",
            " Total de registros individuales sin datos de foros: 4489\n",
            " Total de cursos (curso) sin foros: 145\n",
            "\n",
            " Dataset limpio guardado en: /content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/2. Para unir/merged_cleaned_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Elimina registros sin examen e imputa valores donde el faltante es 5% o menor**"
      ],
      "metadata": {
        "id": "-XWDUgCY_kYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Definir las rutas de los archivos\n",
        "input_path = \"/content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/2. Para unir/merged_cleaned_dataset.csv\"\n",
        "output_path = \"/content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/2. Para unir/merged_exam_cleaned_dataset.csv\"\n",
        "\n",
        "# Cargar el dataset\n",
        "df = pd.read_csv(input_path)\n",
        "\n",
        "# Filtrar registros donde no_exam_data es 1 o 3\n",
        "df = df[~df[\"no_exam_data\"].isin([1, 3])]\n",
        "\n",
        "# Lista de variables referentes a exámenes\n",
        "exam_variables = [\n",
        "    \"total_assigned_exams\", \"total_exams_finished\", \"total_exams_unfinished\", \"exam_submission_rate\",\n",
        "    \"avg_exam_normalized_score\", \"avg_exam_standard_score\", \"max_exam_normalized_score\", \"min_exam_normalized_score\",\n",
        "    \"exam_score_variability\", \"total_perfect_exam_scores\", \"total_questions_answered\", \"total_correct_answers\",\n",
        "    \"total_incorrect_answers\", \"accuracy_rate\", \"total_time_spent_on_exams\", \"avg_exam_time\", \"max_exam_time\",\n",
        "    \"min_exam_time\", \"outlier_exam_attempts\", \"general_outlier_exam_attempts\", \"outlier_exam_rate\", \"total_exam_incidents\",\n",
        "    \"avg_exam_incidents\"\n",
        "]\n",
        "\n",
        "# Obtener la mediana de total_assigned_exams por curso\n",
        "medians = df.groupby(\"curso\")[\"total_assigned_exams\"].median()\n",
        "\n",
        "# Asignar la mediana a los valores NaN en total_assigned_exams para cursos con no_exam_data == 2\n",
        "for curso in df[\"curso\"].unique():\n",
        "    if curso in medians:\n",
        "        median_value = medians[curso] if not pd.isna(medians[curso]) else 1  # Si la mediana es NaN, usar 1\n",
        "\n",
        "        # Imputar total_assigned_exams con la mediana del curso\n",
        "        df.loc[\n",
        "            (df[\"curso\"] == curso) & (df[\"total_assigned_exams\"].isna()),\n",
        "            \"total_assigned_exams\"\n",
        "        ] = median_value\n",
        "\n",
        "        # Imputar total_exams_unfinished con el mismo valor\n",
        "        df.loc[\n",
        "            (df[\"curso\"] == curso) & (df[\"total_exams_unfinished\"].isna()),\n",
        "            \"total_exams_unfinished\"\n",
        "        ] = median_value\n",
        "\n",
        "# Imputar todas las demás variables con 0 si están en NaN\n",
        "for var in exam_variables:\n",
        "    if var not in [\"total_assigned_exams\", \"total_exams_unfinished\"]:\n",
        "        df[var] = df[var].fillna(0)\n",
        "\n",
        "# Guardar el dataset limpio\n",
        "df.to_csv(output_path, index=False)\n",
        "\n",
        "print(\"Dataset procesado y guardado correctamente en:\", output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M42cKdMzAhP6",
        "outputId": "33e4bc0e-7c57-4b50-e7b5-ee89bc557032"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset procesado y guardado correctamente en: /content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/2. Para unir/merged_exam_cleaned_dataset.csv\n"
          ]
        }
      ]
    }
  ]
}