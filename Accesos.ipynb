{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1D4j6I_iFygG__1wQfzFYAJiDBU7tb9zO",
      "authorship_tag": "ABX9TyMsnVhsmAwD7bpsqdwW1of/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikeroguez/experimento/blob/main/Accesos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*1. Normalizar e imputar*"
      ],
      "metadata": {
        "id": "Eb40tl5nIvd1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fFhyC1jGGph",
        "outputId": "6213e6f4-da06-4da3-b80c-0827d7eab143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo procesado y guardado en /content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/1. Para tratar/accesos/accesos_normalizado.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import skew\n",
        "import html\n",
        "import numpy as np\n",
        "\n",
        "# Rutas de entrada y salida\n",
        "INPUT_PATH = \"/content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/1. Para tratar/accesos/accesos.csv\"\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/1. Para tratar/accesos/accesos_normalizado.csv\"\n",
        "\n",
        "# Cargar datos\n",
        "df = pd.read_csv(INPUT_PATH)\n",
        "\n",
        "# Parsear entidades HTML en la columna dispositivo\n",
        "df[\"dispositivo\"] = df[\"dispositivo\"].apply(html.unescape)\n",
        "\n",
        "# Normalizar valores en la columna dispositivo\n",
        "df[\"dispositivo\"] = df[\"dispositivo\"].replace(\"Móvil\", \"Mobile\")\n",
        "\n",
        "# Convertir fechas a formato datetime\n",
        "df[\"fecha_ingreso\"] = pd.to_datetime(df[\"fecha_ingreso\"], errors='coerce')\n",
        "df[\"fecha_egreso\"] = pd.to_datetime(df[\"fecha_egreso\"], errors='coerce')\n",
        "\n",
        "# Filtrar sesiones completas (fecha_egreso no nula y tiempo mayor que 0)\n",
        "sesiones_completas = df[(df[\"fecha_egreso\"].notna()) & (df[\"tiempo\"] > 0)]\n",
        "\n",
        "# Función para calcular skewness evitando errores\n",
        "def safe_skew(x):\n",
        "    if len(x) < 3:  # Si hay menos de 3 valores, no se puede calcular skewness de manera confiable\n",
        "        return np.nan\n",
        "    if x.std() == 0:  # Si todos los valores son idénticos, el skewness debe ser 0\n",
        "        return 0\n",
        "    return skew(x)\n",
        "\n",
        "# Calcular estadísticas por alumno y dispositivo\n",
        "stats = sesiones_completas.groupby([\"email\", \"dispositivo\"])[\"tiempo\"].agg(\n",
        "    media=\"mean\",\n",
        "    mediana=\"median\",\n",
        "    std=\"std\",\n",
        "    skewness=safe_skew,  # Se usa la versión corregida de skew\n",
        "    cv=lambda x: x.std() / x.mean() if x.mean() > 0 else 0\n",
        ").reset_index()\n",
        "\n",
        "# Definir el método de imputación basado en skewness y CV\n",
        "def elegir_metodo(row):\n",
        "    if row[\"cv\"] < 0.5 and (pd.isna(row[\"skewness\"]) or abs(row[\"skewness\"]) < 1):\n",
        "        return \"media\"\n",
        "    else:\n",
        "        return \"mediana\"\n",
        "\n",
        "stats[\"imputation_type\"] = stats.apply(elegir_metodo, axis=1)\n",
        "\n",
        "# Unir las estadísticas al dataset original\n",
        "df = df.merge(stats[[\"email\", \"dispositivo\", \"imputation_type\", \"media\", \"mediana\"]], on=[\"email\", \"dispositivo\"], how=\"left\")\n",
        "\n",
        "# Crear columna is_imputed e inicializar en 0\n",
        "df[\"is_imputed\"] = 0\n",
        "\n",
        "# Función para imputar los valores faltantes directamente en \"tiempo\"\n",
        "def imputar_tiempo(row):\n",
        "    if pd.isna(row[\"fecha_egreso\"]) and row[\"tiempo\"] == 0:\n",
        "        row[\"is_imputed\"] = 1  # Marcar como imputado\n",
        "        if row[\"imputation_type\"] == \"media\":\n",
        "            return row[\"media\"]\n",
        "        elif row[\"imputation_type\"] == \"mediana\":\n",
        "            return row[\"mediana\"]\n",
        "    return row[\"tiempo\"]\n",
        "\n",
        "# Aplicar imputación directamente en \"tiempo\"\n",
        "df[\"tiempo\"] = df.apply(imputar_tiempo, axis=1)\n",
        "\n",
        "# Corregir la columna is_imputed después de la imputación\n",
        "df[\"is_imputed\"] = ((df[\"tiempo\"] > 0) & (pd.isna(df[\"fecha_egreso\"]))).astype(int)\n",
        "\n",
        "# Actualizar la columna fecha_egreso para los datos imputados\n",
        "df[\"fecha_egreso\"] = df.apply(\n",
        "    lambda row: row[\"fecha_ingreso\"] + pd.to_timedelta(row[\"tiempo\"], unit='m')\n",
        "    if row[\"is_imputed\"] == 1 else row[\"fecha_egreso\"],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Guardar el archivo procesado\n",
        "df.to_csv(OUTPUT_PATH, index=False)\n",
        "\n",
        "print(f\"Archivo procesado y guardado en {OUTPUT_PATH}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*2. Consolidar*"
      ],
      "metadata": {
        "id": "UtxBn7XDVcmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Definir rutas de entrada y salida\n",
        "INPUT_PATH = \"/content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/1. Para tratar/accesos/accesos_normalizado.csv\"\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/1. Para tratar/accesos/accesos_consolidado.csv\"\n",
        "\n",
        "# Cargar el dataset\n",
        "df = pd.read_csv(INPUT_PATH)\n",
        "\n",
        "# Asegurar que la columna dispositivo esté bien escrita\n",
        "df[\"dispositivo\"] = df[\"dispositivo\"].str.strip()\n",
        "\n",
        "# Crear nuevas columnas para identificar sesiones desktop y móvil\n",
        "df[\"desktop_sessions\"] = (df[\"dispositivo\"] == \"Desktop\").astype(int)\n",
        "df[\"mobile_sessions\"] = (df[\"dispositivo\"] == \"Mobile\").astype(int)\n",
        "\n",
        "# Crear nuevas columnas para contar sesiones imputadas por tipo de dispositivo\n",
        "df[\"desktop_imputed_sessions\"] = ((df[\"dispositivo\"] == \"Desktop\") & (df[\"is_imputed\"] == 1)).astype(int)\n",
        "df[\"mobile_imputed_sessions\"] = ((df[\"dispositivo\"] == \"Mobile\") & (df[\"is_imputed\"] == 1)).astype(int)\n",
        "\n",
        "# Consolidar los datos por curso y alumno\n",
        "df_consolidado = df.groupby([\"curso\", \"email\", \"groupKey\"], as_index=False).agg({\n",
        "    \"tiempo\": [\"sum\", \"mean\"],  # total_time, average_time\n",
        "    \"fecha_ingreso\": \"nunique\",  # active_days\n",
        "    \"desktop_sessions\": \"sum\",\n",
        "    \"mobile_sessions\": \"sum\",\n",
        "    \"desktop_imputed_sessions\": \"sum\",\n",
        "    \"mobile_imputed_sessions\": \"sum\"\n",
        "})\n",
        "\n",
        "# Renombrar columnas\n",
        "df_consolidado.columns = [\n",
        "    \"curso\", \"email\", \"groupKey\",\n",
        "    \"total_time\", \"average_time\", \"active_days_count\",\n",
        "    \"desktop_sessions_count\", \"mobile_sessions_count\",\n",
        "    \"desktop_imputed_session_time_count\", \"mobile_imputed_session_time_count\"\n",
        "]\n",
        "\n",
        "# Calcular total de sesiones\n",
        "df_consolidado[\"total_sessions_count\"] = df_consolidado[\"desktop_sessions_count\"] + df_consolidado[\"mobile_sessions_count\"]\n",
        "\n",
        "# Calcular total de sesiones imputadas\n",
        "df_consolidado[\"total_imputed_session_time_count\"] = df_consolidado[\"desktop_imputed_session_time_count\"] + df_consolidado[\"mobile_imputed_session_time_count\"]\n",
        "\n",
        "# Calcular la proporción de sesiones imputadas\n",
        "df_consolidado[\"imputed_ratio\"] = df_consolidado[\"total_imputed_session_time_count\"] / df_consolidado[\"total_sessions_count\"]\n",
        "df_consolidado[\"imputed_ratio\"] = df_consolidado[\"imputed_ratio\"].fillna(0)  # Reemplazar valores NaN con 0\n",
        "\n",
        "# Marcar casos extremos: 100% imputación o ≤ 2 sesiones totales\n",
        "df_consolidado[\"extreme_case\"] = ((df_consolidado[\"imputed_ratio\"] == 1.0) | (df_consolidado[\"total_sessions_count\"] <= 2)).astype(int)\n",
        "\n",
        "# Asegurar que la columna extreme_case no tenga valores vacíos\n",
        "df_consolidado[\"extreme_case\"] = df_consolidado[\"extreme_case\"].fillna(0)\n",
        "\n",
        "# Guardar el dataset consolidado\n",
        "df_consolidado.to_csv(OUTPUT_PATH, index=False)\n",
        "\n",
        "print(\"Consolidación completada y guardada en:\", OUTPUT_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-xmuGxxU7CK",
        "outputId": "cf2994aa-8196-497c-f606-30ca36790388"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Consolidación completada y guardada en: /content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/1. Para tratar/accesos/accesos_consolidado.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Lipieza"
      ],
      "metadata": {
        "id": "rSMV9cess_B-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Definir rutas de entrada y salida\n",
        "INPUT_PATH = \"/content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/1. Para tratar/accesos/accesos_consolidado.csv\"\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/1. Para tratar/accesos/accesos_consolidado_cleaned.csv\"\n",
        "\n",
        "# Cargar el dataset consolidado\n",
        "df = pd.read_csv(INPUT_PATH)\n",
        "\n",
        "# Filtrar registros donde extreme_case != 1\n",
        "df_cleaned = df[df[\"extreme_case\"] != 1].drop(columns=[\"extreme_case\"])\n",
        "\n",
        "# Guardar el dataset limpio\n",
        "df_cleaned.to_csv(OUTPUT_PATH, index=False)\n",
        "\n",
        "print(\"Dataset limpio guardado en:\", OUTPUT_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azexjhlIs96s",
        "outputId": "7e179f2a-2224-4132-cb06-bb649e74f12d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset limpio guardado en: /content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/1. Para tratar/accesos/accesos_consolidado_cleaned.csv\n"
          ]
        }
      ]
    }
  ]
}