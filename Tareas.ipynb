{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "13ANsMYRJET3BCF9jqa6wtAWlVnG5j6JI",
      "authorship_tag": "ABX9TyOrFtvzAJpjo0cbJsuNCpwk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikeroguez/experimento/blob/main/Tareas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Codigo para normalizar**"
      ],
      "metadata": {
        "id": "4Wb4l-gvhvds"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cM7HvPG6jwnp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7702964-b7be-4c8d-bca4-24204ec484f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset procesado guardado en: /content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/1. Para tratar/tareas/tareas_normalizado.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import html\n",
        "from typing import Tuple, Optional\n",
        "\n",
        "def get_semester_bounds(commitment_date: pd.Timestamp) -> Tuple[pd.Timestamp, pd.Timestamp]:\n",
        "    \"\"\"Determina los límites del semestre basado en la fecha de compromiso.\"\"\"\n",
        "    if pd.isnull(commitment_date):\n",
        "        return pd.NaT, pd.NaT\n",
        "\n",
        "    year, month = commitment_date.year, commitment_date.month\n",
        "\n",
        "    if 2 <= month <= 7:\n",
        "        return pd.Timestamp(year, 2, 1), pd.Timestamp(year, 7, 31)\n",
        "    elif month == 1:\n",
        "        return pd.Timestamp(year - 1, 8, 1), pd.Timestamp(year, 1, 31)\n",
        "    else:\n",
        "        return pd.Timestamp(year, 8, 1), pd.Timestamp(year + 1, 1, 31)\n",
        "\n",
        "def calculate_delay_days(delivery_date: pd.Timestamp, commitment_date: pd.Timestamp) -> Optional[float]:\n",
        "    \"\"\"Calcula los días de retraso entre la fecha de entrega y la de compromiso.\"\"\"\n",
        "    if pd.isnull(delivery_date) or pd.isnull(commitment_date):\n",
        "        return np.nan\n",
        "    return (delivery_date - commitment_date).days\n",
        "\n",
        "def process_data(input_path: str, output_path: str) -> pd.DataFrame:\n",
        "    \"\"\"Procesa el dataset de tareas académicas y guarda el resultado.\"\"\"\n",
        "    FINAL_COLUMNS = [\n",
        "        'curso', 'groupKey', 'email', 'id_actividad', 'actividad',\n",
        "        'fecha_compromiso', 'fecha_de_entrega', 'calificacion',\n",
        "        'calificacion_normalizada', 'calificacion_estandarizada', 'es_atipico',\n",
        "        'dias_anticipacion', 'fuera_de_rango', 'fue_entregada', 'fue_evaluada', 'tipo_entrega'\n",
        "    ]\n",
        "\n",
        "    # Cargar y preparar los datos\n",
        "    df = pd.read_csv(input_path)\n",
        "    df.rename(columns={\n",
        "        'Fecha_compromiso': 'fecha_compromiso',\n",
        "        'Fecha_de_entrega': 'fecha_de_entrega',\n",
        "        'Calificacion': 'calificacion',\n",
        "        'Actividad': 'actividad'\n",
        "    }, inplace=True)\n",
        "\n",
        "    # Parsear fechas sin tiempo (hora, minuto, segundo)\n",
        "    df['fecha_compromiso'] = pd.to_datetime(df['fecha_compromiso'], errors='coerce').dt.date\n",
        "    df['fecha_de_entrega'] = pd.to_datetime(df['fecha_de_entrega'], errors='coerce').dt.date\n",
        "\n",
        "    # Convertir las fechas de nuevo a datetime para operaciones posteriores\n",
        "    df['fecha_compromiso'] = pd.to_datetime(df['fecha_compromiso'])\n",
        "    df['fecha_de_entrega'] = pd.to_datetime(df['fecha_de_entrega'])\n",
        "\n",
        "    # Limpiar y normalizar la columna 'actividad'\n",
        "    df['actividad'] = (\n",
        "        df['actividad']\n",
        "        .fillna(\"actividad desconocida\")\n",
        "        .apply(lambda x: html.unescape(str(x)))\n",
        "        .str.replace(r'[^\\x00-\\x7F]+', '', regex=True)\n",
        "    )\n",
        "\n",
        "    # Identificar calificaciones atípicas\n",
        "    df['es_atipico'] = ((df['calificacion'] > 100) & df['calificacion'].notna()).astype(int)\n",
        "\n",
        "    # Manejar calificaciones faltantes\n",
        "    df.loc[df['fecha_de_entrega'].isna() | (df['fecha_de_entrega'].notna() & df['calificacion'].isna()), 'calificacion'] = np.nan\n",
        "\n",
        "    # Normalizar calificaciones\n",
        "    max_scores = df[df['calificacion'] >= 0].groupby('id_actividad')['calificacion'].max()\n",
        "    df['calificacion_normalizada'] = (\n",
        "        df.apply(lambda x: (x['calificacion'] / max_scores.get(x['id_actividad'], np.nan)) * 10\n",
        "                 if pd.notnull(x['calificacion']) and max_scores.get(x['id_actividad'], 0) > 0\n",
        "                 else np.nan, axis=1)\n",
        "        .round(2)\n",
        "    )\n",
        "\n",
        "    # Estandarizar calificaciones\n",
        "    actividad_stats = df.groupby('id_actividad')['calificacion'].agg(mean='mean', std='std', count='count')\n",
        "    df = df.merge(actividad_stats, left_on='id_actividad', right_index=True, how='left')\n",
        "    df['calificacion_estandarizada'] = np.where(\n",
        "        df['count'] < 2,\n",
        "        np.nan,\n",
        "        ((df['calificacion'] - df['mean']) / df['std'].replace(0, np.nan)).round(2)\n",
        "    )\n",
        "\n",
        "    # Calcular límites del semestre y días de anticipación\n",
        "    df[['semester_start', 'semester_end']] = df['fecha_compromiso'].apply(lambda x: pd.Series(get_semester_bounds(x)))\n",
        "    df['dias_anticipacion'] = (df['fecha_compromiso'] - df['fecha_de_entrega']).dt.days\n",
        "\n",
        "    # Calcular si la entrega está fuera de rango y convertir a 0/1\n",
        "    df['fuera_de_rango'] = df.apply(\n",
        "        lambda x: (\n",
        "            pd.notna(x['fecha_de_entrega']) and\n",
        "            pd.notna(x['semester_start']) and\n",
        "            pd.notna(x['semester_end']) and\n",
        "            (x['fecha_de_entrega'] < x['semester_start'] or x['fecha_de_entrega'] > x['semester_end'])\n",
        "        ),\n",
        "        axis=1\n",
        "    ).astype(int)  # Convertir a 0/1\n",
        "\n",
        "    # Clasificar el tipo de entrega\n",
        "    df['tipo_entrega'] = np.select(\n",
        "        [\n",
        "            df['fecha_de_entrega'].isna(),\n",
        "            df['dias_anticipacion'] > 7,\n",
        "            df['dias_anticipacion'].between(0, 7),\n",
        "            df['dias_anticipacion'] < 0\n",
        "        ],\n",
        "        ['faltante', 'temprana', 'puntual', 'tardía'],\n",
        "        default='desconocida'\n",
        "    )\n",
        "\n",
        "    # Indicadores de entrega y evaluación\n",
        "    df['fue_entregada'] = df['fecha_de_entrega'].notna().astype(int)\n",
        "    df['fue_evaluada'] = df['calificacion'].notna().astype(int)\n",
        "\n",
        "    return df[FINAL_COLUMNS].copy()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    INPUT_PATH = \"/content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/1. Para tratar/tareas/tareas.csv\"\n",
        "    OUTPUT_PATH = \"/content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/1. Para tratar/tareas/tareas_normalizado.csv\"\n",
        "\n",
        "    processed_df = process_data(INPUT_PATH, OUTPUT_PATH)\n",
        "    processed_df.to_csv(OUTPUT_PATH, index=False)\n",
        "    print(f\"Dataset procesado guardado en: {OUTPUT_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Código para consolidar**"
      ],
      "metadata": {
        "id": "RmZfYPEOh1Z_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar el dataset desde Google Drive\n",
        "file_path = \"/content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/1. Para tratar/tareas/tareas_normalizado.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Función para consolidar los datos con cálculos consistentes\n",
        "def consolidate_data_fixed(data):\n",
        "    # Agrupar y calcular métricas principales\n",
        "    consolidated = data.groupby(['curso', 'email', 'groupKey']).agg(\n",
        "        total_assignments=('id_actividad', 'count'),\n",
        "        avg_assignment_normalized_score=('calificacion_normalizada', 'mean'),\n",
        "        avg_assignment_estandard_score=('calificacion_estandarizada', 'mean'),\n",
        "        max_assignment_normalized_score=('calificacion_normalizada', 'max'),\n",
        "        min_assignment_normalized_score=('calificacion_normalizada', 'min'),\n",
        "        max_assignment_estandard_score=('calificacion_estandarizada', 'max'),\n",
        "        min_assignment_estandard_score=('calificacion_estandarizada', 'min'),\n",
        "        score_variability=('calificacion_normalizada', 'std'),\n",
        "        total_graded_assignments=('fue_evaluada', 'sum'),\n",
        "        total_submitted_assignments=('fue_entregada', 'sum'),\n",
        "        total_missing_assignments=('fue_entregada', lambda x: (x == 0).sum()),\n",
        "        total_ungraded_assignments=('fue_evaluada', lambda x: (x == 0).sum()),\n",
        "        total_out_of_range_assignments=('fuera_de_rango', 'sum'),\n",
        "        total_late_assignments=('tipo_entrega', lambda x: (x == 'tardía').sum()),\n",
        "        avg_submission_delay_days=(\n",
        "            'dias_anticipacion',\n",
        "            lambda x: x[data.loc[x.index, 'fue_entregada'] == 1].mean() if not x.empty else 0\n",
        "        )\n",
        "    ).reset_index()\n",
        "\n",
        "    # Calcular tasas y métricas derivadas\n",
        "    consolidated['assignment_submission_rate'] = (\n",
        "        consolidated['total_submitted_assignments'] / consolidated['total_assignments']\n",
        "    )\n",
        "    consolidated['assignment_procrastination_rate'] = (\n",
        "        consolidated['total_late_assignments'] / consolidated['total_submitted_assignments']\n",
        "    )\n",
        "\n",
        "    # Calcular rendimiento general ponderado\n",
        "    w1, w2 = 0.5, 0.5\n",
        "    consolidated['overall_assignment_performance'] = (\n",
        "        (consolidated['avg_assignment_normalized_score'] * w1) +\n",
        "        (consolidated['assignment_submission_rate'] * 10 * w2)\n",
        "    )\n",
        "\n",
        "    # Clasificar rendimiento general\n",
        "    def classify_general_performance(overall_score):\n",
        "        if overall_score >= 9.0:\n",
        "            return 'Excelente'\n",
        "        elif overall_score >= 8.0:\n",
        "            return 'Bien'\n",
        "        elif overall_score >= 6.0:\n",
        "            return 'Suficiente'\n",
        "        else:\n",
        "            return 'Insuficiente'\n",
        "\n",
        "    consolidated['overall_assignment_performance_classification'] = (\n",
        "        consolidated['overall_assignment_performance'].apply(classify_general_performance)\n",
        "    )\n",
        "\n",
        "    # Revisar si todos los trabajos del grupo no fueron calificados\n",
        "    group_status = consolidated.groupby(['curso', 'groupKey'])['total_graded_assignments'].sum().reset_index()\n",
        "    group_status['delete'] = group_status['total_graded_assignments'].apply(lambda x: 1 if x == 0 else 0)\n",
        "\n",
        "    # Unir el estado del grupo al DataFrame consolidado\n",
        "    consolidated = pd.merge(\n",
        "        consolidated, group_status[['curso', 'groupKey', 'delete']],\n",
        "        on=['curso', 'groupKey'], how='left'\n",
        "    )\n",
        "\n",
        "    return consolidated\n",
        "\n",
        "# Aplicar la función para consolidar los datos\n",
        "corrected_consolidated_data = consolidate_data_fixed(data)\n",
        "\n",
        "# Guardar los datos consolidados corregidos\n",
        "output_path_corrected = \"/content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/1. Para tratar/tareas/tareas_consolidado.csv\"\n",
        "corrected_consolidated_data.to_csv(output_path_corrected, index=False)\n",
        "\n",
        "#print(f\"Datos consolidados guardados en: {output_path_corrected}\")\n",
        "\n",
        "# Mostrar los primeros registros\n",
        "#print(corrected_consolidated_data.head())\n",
        "\n",
        "print(f\"Archivo consolidado guardado en: {output_path_corrected}\")\n"
      ],
      "metadata": {
        "id": "Wio0XzPJS3JZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Código para limpiar**"
      ],
      "metadata": {
        "id": "zrNj_50Qh6ox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ruta del archivo de entrada y salida\n",
        "input_file = \"/content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/1. Para tratar/tareas/tareas_consolidado.csv\"\n",
        "output_file = \"/content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/1. Para tratar/tareas/tareas_consolidado_cleaned.csv\"\n",
        "\n",
        "# Cargar el archivo consolidado\n",
        "data = pd.read_csv(input_file)\n",
        "\n",
        "# Filtrar registros donde delete = 1\n",
        "def filter_data(data):\n",
        "    return data[data['delete'] != 1].copy()\n",
        "\n",
        "# Manejar valores nulos e imputar\n",
        "def handle_missing_values(data):\n",
        "    # Imputar valores nulos en las columnas relevantes\n",
        "    fill_zero_columns = [\n",
        "        'avg_assignment_normalized_score', 'avg_assignment_estandard_score',\n",
        "        'max_assignment_normalized_score', 'min_assignment_normalized_score',\n",
        "        'max_assignment_estandard_score', 'min_assignment_estandard_score',\n",
        "        'score_variability', 'avg_submission_delay_days',\n",
        "        'assignment_procrastination_rate', 'overall_assignment_performance'\n",
        "    ]\n",
        "    data[fill_zero_columns] = data[fill_zero_columns].fillna(0)\n",
        "\n",
        "    # Crear una bandera para alumnos con una sola tarea entregada\n",
        "    data['single_submission_flag'] = (data['total_submitted_assignments'] == 1).astype(int)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Aplicar el pipeline\n",
        "data_filtered = filter_data(data)\n",
        "data_cleaned = handle_missing_values(data_filtered)\n",
        "\n",
        "# Guardar el archivo limpio\n",
        "data_cleaned.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Archivo limpio guardado en: {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z-MTIv_eKSZ",
        "outputId": "429ec832-c64b-4fd4-fbcb-fcb8979278eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo limpio guardado en: /content/drive/MyDrive/Doctorado/Experimentos/Datos/DSv4.0/1. Para tratar/tareas/tareas_consolidado_cleaned.csv\n"
          ]
        }
      ]
    }
  ]
}